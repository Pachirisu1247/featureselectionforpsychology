
@article{probst_hyperparameters_2019,
	title = {Hyperparameters and {Tuning} {Strategies} for {Random} {Forest}},
	volume = {9},
	issn = {1942-4787, 1942-4795},
	url = {http://arxiv.org/abs/1804.03515},
	doi = {10.1002/widm.1301},
	abstract = {The random forest algorithm (RF) has several hyperparameters that have to be set by the user, e.g., the number of observations drawn randomly for each tree and whether they are drawn with or without replacement, the number of variables drawn randomly for each split, the splitting rule, the minimum number of samples that a node must contain and the number of trees. In this paper, we first provide a literature review on the parameters' influence on the prediction performance and on variable importance measures. It is well known that in most cases RF works reasonably well with the default values of the hyperparameters specified in software packages. Nevertheless, tuning the hyperparameters can improve the performance of RF. In the second part of this paper, after a brief overview of tuning strategies we demonstrate the application of one of the most established tuning strategies, model-based optimization (MBO). To make it easier to use, we provide the tuneRanger R package that tunes RF with MBO automatically. In a benchmark study on several datasets, we compare the prediction performance and runtime of tuneRanger with other tuning implementations in R and RF with default hyperparameters.},
	number = {3},
	urldate = {2025-02-26},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Probst, Philipp and Wright, Marvin and Boulesteix, Anne-Laure},
	month = may,
	year = {2019},
	note = {arXiv:1804.03515 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {e1301},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/QRQHKKGT/Probst et al. - 2019 - Hyperparameters and Tuning Strategies for Random Forest.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/MFTW8AVS/1804.html:text/html},
}

@article{barrenada_understanding_2024,
	title = {Understanding overfitting in random forest for probability estimation: a visualization and simulation study},
	volume = {8},
	issn = {2397-7523},
	shorttitle = {Understanding overfitting in random forest for probability estimation},
	url = {http://arxiv.org/abs/2402.18612},
	doi = {10.1186/s41512-024-00177-1},
	abstract = {Random forests have become popular for clinical risk prediction modelling. In a case study on predicting ovarian malignancy, we observed training c-statistics close to 1. Although this suggests overfitting, performance was competitive on test data. We aimed to understand the behaviour of random forests by (1) visualizing data space in three real world case studies and (2) a simulation study. For the case studies, risk estimates were visualised using heatmaps in a 2-dimensional subspace. The simulation study included 48 logistic data generating mechanisms (DGM), varying the predictor distribution, the number of predictors, the correlation between predictors, the true c-statistic and the strength of true predictors. For each DGM, 1000 training datasets of size 200 or 4000 were simulated and RF models trained with minimum node size 2 or 20 using ranger package, resulting in 192 scenarios in total. The visualizations suggested that the model learned spikes of probability around events in the training set. A cluster of events created a bigger peak, isolated events local peaks. In the simulation study, median training c-statistics were between 0.97 and 1 unless there were 4 or 16 binary predictors with minimum node size 20. Median test c-statistics were higher with higher events per variable, higher minimum node size, and binary predictors. Median training slopes were always above 1, and were not correlated with median test slopes across scenarios (correlation -0.11). Median test slopes were higher with higher true c-statistic, higher minimum node size, and higher sample size. Random forests learn local probability peaks that often yield near perfect training c-statistics without strongly affecting c-statistics on test data. When the aim is probability estimation, the simulation results go against the common recommendation to use fully grown trees in random forest models.},
	number = {1},
	urldate = {2025-02-26},
	journal = {Diagnostic and Prognostic Research},
	author = {Barreñada, Lasai and Dhiman, Paula and Timmerman, Dirk and Boulesteix, Anne-Laure and Calster, Ben Van},
	month = sep,
	year = {2024},
	note = {arXiv:2402.18612 [stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computers and Society, Statistics - Methodology},
	pages = {14},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/9Y9N2LKU/Barreñada et al. - 2024 - Understanding overfitting in random forest for probability estimation a visualization and simulatio.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/SDRGPSVY/2402.html:text/html},
}

@article{strobl_bias_2007,
	title = {Bias in random forest variable importance measures: {Illustrations}, sources and a solution},
	volume = {8},
	issn = {1471-2105},
	shorttitle = {Bias in random forest variable importance measures},
	url = {https://doi.org/10.1186/1471-2105-8-25},
	doi = {10.1186/1471-2105-8-25},
	abstract = {Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.},
	number = {1},
	urldate = {2025-02-26},
	journal = {BMC Bioinformatics},
	author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
	month = jan,
	year = {2007},
	keywords = {Bootstrap Sampling, Importance Measure, Random Forest, Variable Importance, Variable Selection},
	pages = {25},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/X5K4DXYM/Strobl et al. - 2007 - Bias in random forest variable importance measures Illustrations, sources and a solution.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/7F2BYZTN/1471-2105-8-25.html:text/html},
}

@article{shmueli_explain_2010,
	title = {To {Explain} or to {Predict}?},
	volume = {25},
	issn = {0883-4237},
	url = {https://projecteuclid.org/journals/statistical-science/volume-25/issue-3/To-Explain-or-to-Predict/10.1214/10-STS330.full},
	doi = {10.1214/10-STS330},
	abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conﬂation between explanation and prediction is common, yet the distinction must be understood for progressing scientiﬁc knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
	language = {en},
	number = {3},
	urldate = {2025-02-26},
	journal = {Statistical Science},
	author = {Shmueli, Galit},
	month = aug,
	year = {2010},
	file = {PDF:/Users/frankie/Zotero/storage/GRNDAGLR/Shmueli - 2010 - To Explain or to Predict.pdf:application/pdf},
}

@article{genuer_variable_2010,
	title = {Variable selection using random forests},
	volume = {31},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865510000954},
	doi = {10.1016/j.patrec.2010.03.014},
	abstract = {This paper proposes, focusing on random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001, to investigate two classical issues of variable selection. The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good parsimonious prediction model. The main contribution is twofold: to provide some experimental insights about the behavior of the variable importance index based on random forests and to propose a strategy involving a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy.},
	number = {14},
	urldate = {2025-02-26},
	journal = {Pattern Recognition Letters},
	author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau-Malot, Christine},
	month = oct,
	year = {2010},
	keywords = {Classification, High dimensional data, Random forests, Regression, Variable importance, Variable selection},
	pages = {2225--2236},
	file = {ScienceDirect Snapshot:/Users/frankie/Zotero/storage/K4UPSVDU/S0167865510000954.html:text/html;Submitted Version:/Users/frankie/Zotero/storage/JAXEEEK3/Genuer et al. - 2010 - Variable selection using random forests.pdf:application/pdf},
}

@article{degenhardt_evaluation_2019,
	title = {Evaluation of variable selection methods for random forests and omics data sets},
	volume = {20},
	issn = {1477-4054},
	url = {https://doi.org/10.1093/bib/bbx124},
	doi = {10.1093/bib/bbx124},
	abstract = {Machine learning methods and in particular random forests are promising approaches for prediction based on high dimensional omics data sets. They provide variable importance measures to rank predictors according to their predictive power. If building a prediction model is the main goal of a study, often a minimal set of variables with good prediction performance is selected. However, if the objective is the identification of involved variables to find active networks and pathways, approaches that aim to select all relevant variables should be preferred. We evaluated several variable selection procedures based on simulated data as well as publicly available experimental methylation and gene expression data. Our comparison included the Boruta algorithm, the Vita method, recurrent relative variable importance, a permutation approach and its parametric variant (Altmann) as well as recursive feature elimination (RFE). In our simulation studies, Boruta was the most powerful approach, followed closely by the Vita method. Both approaches demonstrated similar stability in variable selection, while Vita was the most robust approach under a pure null model without any predictor variables related to the outcome. In the analysis of the different experimental data sets, Vita demonstrated slightly better stability in variable selection and was less computationally intensive than Boruta.In conclusion, we recommend the Boruta and Vita approaches for the analysis of high-dimensional data sets. Vita is considerably faster than Boruta and thus more suitable for large data sets, but only Boruta can also be applied in low-dimensional settings.},
	number = {2},
	urldate = {2025-02-26},
	journal = {Briefings in Bioinformatics},
	author = {Degenhardt, Frauke and Seifert, Stephan and Szymczak, Silke},
	month = mar,
	year = {2019},
	pages = {492--503},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/K8BLNNGJ/Degenhardt et al. - 2019 - Evaluation of variable selection methods for random forests and omics data sets.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/MIUBT9W2/4554516.html:text/html},
}

@article{speiser_comparison_2019,
	title = {A comparison of random forest variable selection methods for classification prediction modeling},
	volume = {134},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417419303574},
	doi = {10.1016/j.eswa.2019.05.028},
	abstract = {Random forest classification is a popular machine learning method for developing prediction models in many research settings. Often in prediction modeling, a goal is to reduce the number of variables needed to obtain a prediction in order to reduce the burden of data collection and improve efficiency. Several variable selection methods exist for the setting of random forest classification; however, there is a paucity of literature to guide users as to which method may be preferable for different types of datasets. Using 311 classification datasets freely available online, we evaluate the prediction error rates, number of variables, computation times and area under the receiver operating curve for many random forest variable selection methods. We compare random forest variable selection methods for different types of datasets (datasets with binary outcomes, datasets with many predictors, and datasets with imbalanced outcomes) and for different types of methods (standard random forest versus conditional random forest methods and test based versus performance based methods). Based on our study, the best variable selection methods for most datasets are Jiang's method and the method implemented in the VSURF R package. For datasets with many predictors, the methods implemented in the R packages varSelRF and Boruta are preferable due to computational efficiency. A significant contribution of this study is the ability to assess different variable selection techniques in the setting of random forest classification in order to identify preferable methods based on applications in expert and intelligent systems.},
	urldate = {2025-02-26},
	journal = {Expert Systems with Applications},
	author = {Speiser, Jaime Lynn and Miller, Michael E. and Tooze, Janet and Ip, Edward},
	month = nov,
	year = {2019},
	keywords = {Classification, Variable selection, Feature reduction, Random forest},
	pages = {93--101},
	file = {PubMed Central Full Text PDF:/Users/frankie/Zotero/storage/E9I292SJ/Speiser et al. - 2019 - A comparison of random forest variable selection methods for classification prediction modeling.pdf:application/pdf;ScienceDirect Snapshot:/Users/frankie/Zotero/storage/MJF6DMCW/S0957417419303574.html:text/html},
}

@article{wallace_use_2023,
	title = {Use and misuse of random forest variable importance metrics in medicine: demonstrations through incident stroke prediction},
	volume = {23},
	issn = {1471-2288},
	shorttitle = {Use and misuse of random forest variable importance metrics in medicine},
	url = {https://doi.org/10.1186/s12874-023-01965-x},
	doi = {10.1186/s12874-023-01965-x},
	abstract = {Machine learning tools such as random forests provide important opportunities for modeling large, complex modern data generated in medicine. Unfortunately, when it comes to understanding why machine learning models are predictive, applied research continues to rely on ‘out of bag’ (OOB) variable importance metrics (VIMPs) that are known to have considerable shortcomings within the statistics community. After explaining the limitations of OOB VIMPs – including bias towards correlated features and limited interpretability – we describe a modern approach called ‘knockoff VIMPs’ and explain its advantages.},
	number = {1},
	urldate = {2025-02-26},
	journal = {BMC Medical Research Methodology},
	author = {Wallace, Meredith L. and Mentch, Lucas and Wheeler, Bradley J. and Tapia, Amanda L. and Richards, Marc and Zhou, Siyu and Yi, Lixia and Redline, Susan and Buysse, Daniel J.},
	month = jun,
	year = {2023},
	keywords = {Random forest, Feature importance, Knockoff variable importance, Polysomnography, Sleep},
	pages = {144},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/JIWS2FWM/Wallace et al. - 2023 - Use and misuse of random forest variable importance metrics in medicine demonstrations through inci.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/A32F7FNF/s12874-023-01965-x.html:text/html},
}

@article{ishwaran_standard_2019,
	title = {Standard errors and confidence intervals for variable importance in random forest regression, classification, and survival},
	volume = {38},
	issn = {0277-6715},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6279615/},
	doi = {10.1002/sim.7803},
	abstract = {Random forests is a popular nonparametric tree ensemble procedure with broad applications to data analysis. While RF’s widespread popularity stems from its prediction performance, an equally important feature is that it provides a fully nonparametric measure of variable importance (VIMP). A current limitation of VIMP however is that no systematic method exists for estimating its variance. As a solution, we propose a subsampling approach that can be used to estimate the variance of VIMP and for constructing confidence intervals. The method is general enough that it can be applied to many useful settings, including regression, classification, and survival problems. Using extensive simulations we demonstrate the effectiveness of the subsampling estimator and in particular find that the delete-d jackknife variance estimator, a close cousin, is especially effective under low subsampling rates due to its bias correction properties. These two estimators are highly competitive when compared to the .164 bootstrap estimator, a modified bootstrap procedure designed to deal with ties in out-of-sample data. Most importantly, subsampling is computationally fast, thus making it especially attractive for big data settings.},
	number = {4},
	urldate = {2025-02-26},
	journal = {Statistics in medicine},
	author = {Ishwaran, Hemant and Lu, Min},
	month = feb,
	year = {2019},
	pmid = {29869423},
	pmcid = {PMC6279615},
	pages = {558--582},
	file = {PubMed Central Full Text PDF:/Users/frankie/Zotero/storage/NYN4VFPH/Ishwaran and Lu - 2019 - Standard errors and confidence intervals for variable importance in random forest regression, classi.pdf:application/pdf},
}

@article{gromping_variable_2009,
	title = {Variable {Importance} {Assessment} in {Regression}: {Linear} {Regression} versus {Random} {Forest}},
	volume = {63},
	issn = {0003-1305, 1537-2731},
	shorttitle = {Variable {Importance} {Assessment} in {Regression}},
	url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2009.08199},
	doi = {10.1198/tast.2009.08199},
	language = {en},
	number = {4},
	urldate = {2025-02-26},
	journal = {The American Statistician},
	author = {Grömping, Ulrike},
	month = nov,
	year = {2009},
	pages = {308--319},
	file = {PDF:/Users/frankie/Zotero/storage/H792F8NE/Grömping - 2009 - Variable Importance Assessment in Regression Linear Regression versus Random Forest.pdf:application/pdf},
}

@article{van_der_ploeg_modern_2014,
	title = {Modern modelling techniques are data hungry: a simulation study for predicting dichotomous endpoints},
	volume = {14},
	issn = {1471-2288},
	shorttitle = {Modern modelling techniques are data hungry},
	url = {https://doi.org/10.1186/1471-2288-14-137},
	doi = {10.1186/1471-2288-14-137},
	abstract = {Modern modelling techniques may potentially provide more accurate predictions of binary outcomes than classical techniques. We aimed to study the predictive performance of different modelling techniques in relation to the effective sample size (“data hungriness”).},
	number = {1},
	urldate = {2025-02-26},
	journal = {BMC Medical Research Methodology},
	author = {van der Ploeg, Tjeerd and Austin, Peter C. and Steyerberg, Ewout W.},
	month = dec,
	year = {2014},
	keywords = {Random Forest, Data Hungriness, Modelling Technique, Reference Model, Support Vector Machine},
	pages = {137},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/LDM5DJ9T/van der Ploeg et al. - 2014 - Modern modelling techniques are data hungry a simulation study for predicting dichotomous endpoints.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/AM5VSBYM/1471-2288-14-137.html:text/html},
}

@article{wallert_predicting_2018,
	title = {Predicting {Adherence} to {Internet}-{Delivered} {Psychotherapy} for {Symptoms} of {Depression} and {Anxiety} {After} {Myocardial} {Infarction}: {Machine} {Learning} {Insights} {From} the {U}-{CARE} {Heart} {Randomized} {Controlled} {Trial}},
	volume = {20},
	shorttitle = {Predicting {Adherence} to {Internet}-{Delivered} {Psychotherapy} for {Symptoms} of {Depression} and {Anxiety} {After} {Myocardial} {Infarction}},
	url = {https://www.jmir.org/2018/10/e10754},
	doi = {10.2196/10754},
	abstract = {Background: Low adherence to recommended treatments is a multifactorial problem for patients in rehabilitation after myocardial infarction (MI). In a nationwide trial of internet-delivered cognitive behavior therapy (iCBT) for the high-risk subgroup of patients with MI also reporting symptoms of anxiety, depression, or both (MI-ANXDEP), adherence was low. Since low adherence to psychotherapy leads to a waste of therapeutic resources and risky treatment abortion in MI-ANXDEP patients, identifying early predictors for adherence is potentially valuable for effective targeted care. Objectives: The goal of the research was to use supervised machine learning to investigate both established and novel predictors for iCBT adherence in MI-ANXDEP patients. Methods: Data were from 90 MI-ANXDEP patients recruited from 25 hospitals in Sweden and randomized to treatment in the iCBT trial Uppsala University Psychosocial Care Programme (U-CARE) Heart study. Time point of prediction was at completion of the first homework assignment. Adherence was defined as having completed more than 2 homework assignments within the 14-week treatment period. A supervised machine learning procedure was applied to identify the most potent predictors for adherence available at the first treatment session from a range of demographic, clinical, psychometric, and linguistic predictors. The internal binary classifier was a random forest model within a 3×10–fold cross-validated recursive feature elimination (RFE) resampling which selected the final predictor subset that best differentiated adherers versus nonadherers. Results: Patient mean age was 58.4 years (SD 9.4), 62\% (56/90) were men, and 48\% (43/90) were adherent. Out of the 34 potential predictors for adherence, RFE selected an optimal subset of 56\% (19/34; Accuracy 0.64, 95\% CI 0.61-0.68, P{\textless}.001). The strongest predictors for adherence were, in order of importance, (1) self-assessed cardiac-related fear, (2) sex, and (3) the number of words the patient used to answer the first homework assignment. Conclusions: For developing and testing effective iCBT interventions, investigating factors that predict adherence is important. Adherence to iCBT for MI-ANXDEP patients in the U-CARE Heart trial was best predicted by cardiac-related fear and sex, consistent with previous research, but also by novel linguistic predictors from written patient behavior which conceivably indicate verbal ability or therapeutic alliance. Future research should investigate potential causal mechanisms and seek to determine what underlying constructs the linguistic predictors tap into. Whether these findings replicate for other interventions outside of Sweden, in larger samples, and for patients with other conditions who are offered iCBT should also be investigated. Trial registration: ClinicalTrials.gov NCT01504191; https://clinicaltrials.gov/ct2/show/NCT01504191 (Archived at Webcite at http://www.webcitation.org/6xWWSEQ22)},
	language = {EN},
	number = {10},
	urldate = {2025-02-26},
	journal = {Journal of Medical Internet Research},
	author = {Wallert, John and Gustafson, Emelie and Held, Claes and Madison, Guy and Norlund, Fredrika and Essen, Louise von and Olsson, Erik Martin Gustaf},
	month = oct,
	year = {2018},
	note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e10754},
	file = {Snapshot:/Users/frankie/Zotero/storage/GLFQ7F6S/e10754.html:text/html;Submitted Version:/Users/frankie/Zotero/storage/U9F79ETD/Wallert et al. - 2018 - Predicting Adherence to Internet-Delivered Psychotherapy for Symptoms of Depression and Anxiety Afte.pdf:application/pdf},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	copyright = {Kluwer Academic Publishers 2001},
	issn = {08856125},
	url = {https://www.proquest.com/docview/757027982/abstract/CC3A3A649E1C49A6PQ/1},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.[PUBLICATION ABSTRACT]},
	language = {English},
	number = {1},
	urldate = {2025-02-26},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	note = {Num Pages: 5-32
Place: Dordrecht, Netherlands
Publisher: Springer Nature B.V.},
	keywords = {Random forest, Correlation, Forest, Forests, Generalization error, Randomness, Strength, Studies, Trees},
	pages = {5--32},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/74WAU7HC/Breiman - 2001 - Random Forests.pdf:application/pdf},
}

@article{cipora_amatus_2024,
	title = {The {AMATUS} {Dataset}: {Arithmetic} {Performance}, {Mathematics} {Anxiety} and {Attitudes} in {Primary} {School} {Teachers} and {University} {Students}},
	volume = {12},
	issn = {2050-9863},
	shorttitle = {The {AMATUS} {Dataset}},
	url = {https://openpsychologydata.metajnl.com/articles/10.5334/jopd.115},
	doi = {10.5334/jopd.115},
	abstract = {Although the mathematics anxiety-performance link has been extensively studied, its interplay with other emotional and attitude constructs is still unclear. The present dataset includes measures of mathematics anxiety and arithmetic performance alongside different types of anxiety (i.e., state, test, general anxiety and neuroticism), attitudes towards mathematics (i.e., mathematics self-concept, mathematics self-efficacy and mathematics-gender stereotype endorsement), and math-unrelated constructs among university students (N = 848) and primary school teachers (N = 258) from Germany and Belgium. The data is accessible in the Open Science Framework (https://osf.io/gszpb/).},
	language = {en-US},
	number = {1},
	urldate = {2025-02-26},
	journal = {Journal of Open Psychology Data},
	author = {Cipora, Krzysztof and Lunardon, Maristella and Masson, Nicolas and Georges, Carrie and Nuerk, Hans-Christoph and Artemenko, Christina},
	month = sep,
	year = {2024},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/D98AXFT8/Cipora et al. - 2024 - The AMATUS Dataset Arithmetic Performance, Mathematics Anxiety and Attitudes in Primary School Teac.pdf:application/pdf},
}

@misc{organisation_for_economic_co-operation_and_development_internationaler_2012,
	title = {Internationaler {Schülerfragebogen} {PISA} 2012 [{International} student questionnaire {PISA} 2012]},
	url = {https://www.iqs.gv.at/downloads/internationale-studien/pisa/pisa-2012},
	language = {German},
	author = {{Organisation for Economic Co-operation and Development}},
	year = {2012},
}

@misc{genuer_random_2008,
	title = {Random {Forests}: some methodological insights},
	shorttitle = {Random {Forests}},
	url = {http://arxiv.org/abs/0811.3619},
	doi = {10.48550/arXiv.0811.3619},
	abstract = {This paper examines from an experimental perspective random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001. It first aims at confirming, known but sparse, advice for using random forests and at proposing some complementary remarks for both standard problems as well as high dimensional ones for which the number of variables hugely exceeds the sample size. But the main contribution of this paper is twofold: to provide some insights about the behavior of the variable importance index based on random forests and in addition, to propose to investigate two classical issues of variable selection. The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good prediction model. The strategy involves a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy.},
	urldate = {2025-02-26},
	publisher = {arXiv},
	author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau, Christine},
	month = nov,
	year = {2008},
	note = {arXiv:0811.3619 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/NBRZDNBU/Genuer et al. - 2008 - Random Forests some methodological insights.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/YHSKGCE6/0811.html:text/html},
}

@article{martinez-munoz_outbag_2010,
	title = {Out-of-bag estimation of the optimal sample size in bagging},
	volume = {43},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S003132030900212X},
	doi = {10.1016/j.patcog.2009.05.010},
	abstract = {The performance of m-out-of-n bagging with and without replacement in terms of the sampling ratio (m/n) is analyzed. Standard bagging uses resampling with replacement to generate bootstrap samples of equal size as the original training set mwor=n. Without-replacement methods typically use half samples mwr=n/2. These choices of sampling sizes are arbitrary and need not be optimal in terms of the classification performance of the ensemble. We propose to use the out-of-bag estimates of the generalization accuracy to select a near-optimal value for the sampling ratio. Ensembles of classifiers trained on independent samples whose size is such that the out-of-bag error of the ensemble is as low as possible generally improve the performance of standard bagging and can be efficiently built.},
	number = {1},
	urldate = {2025-02-26},
	journal = {Pattern Recognition},
	author = {Martínez-Muñoz, Gonzalo and Suárez, Alberto},
	month = jan,
	year = {2010},
	keywords = {Bagging, Bootstrap sampling, Decision trees, Ensembles of classifiers, Optimal sampling ratio, Subagging, Subsampling},
	pages = {143--152},
	file = {Accepted Version:/Users/frankie/Zotero/storage/X3DH2TYT/Martínez-Muñoz and Suárez - 2010 - Out-of-bag estimation of the optimal sample size in bagging.pdf:application/pdf},
}

@article{janitza_overestimation_2018,
	title = {On the overestimation of random forest’s out-of-bag error},
	volume = {13},
	copyright = {© 2018 Janitza, Hornung. This is an open access article distributed under the terms of the Creative Commons Attribution License: http://creativecommons.org/licenses/by/4.0/ (the “License”), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
	url = {https://www.proquest.com/docview/2084328030/abstract/2342C60F664E4E58PQ/1},
	doi = {10.1371/journal.pone.0201904},
	abstract = {The ensemble method random forests has become a popular classification tool in bioinformatics and related fields. The out-of-bag error is an error estimation technique often used to evaluate the accuracy of a random forest and to select appropriate values for tuning parameters, such as the number of candidate predictors that are randomly drawn for a split, referred to as mtry. However, for binary classification problems with metric predictors it has been shown that the out-of-bag error can overestimate the true prediction error depending on the choices of random forests parameters. Based on simulated and real data this paper aims to identify settings for which this overestimation is likely. It is, moreover, questionable whether the out-of-bag error can be used in classification tasks for selecting tuning parameters like mtry, because the overestimation is seen to depend on the parameter mtry. The simulation-based and real-data based studies with metric predictor variables performed in this paper show that the overestimation is largest in balanced settings and in settings with few observations, a large number of predictor variables, small correlations between predictors and weak effects. There was hardly any impact of the overestimation on tuning parameter selection. However, although the prediction performance of random forests was not substantially affected when using the out-of-bag error for tuning parameter selection in the present studies, one cannot be sure that this applies to all future data. For settings with metric predictor variables it is therefore strongly recommended to use stratified subsampling with sampling fractions that are proportional to the class sizes for both tuning parameter selection and error estimation in random forests. This yielded less biased estimates of the true prediction error. In unbalanced settings, in which there is a strong interest in predicting observations from the smaller classes well, sampling the same number of observations from each class is a promising alternative.},
	language = {English},
	number = {8},
	urldate = {2025-02-26},
	journal = {PLoS One},
	author = {Janitza, Silke and Hornung, Roman},
	month = aug,
	year = {2018},
	note = {Num Pages: e0201904
Place: San Francisco, United States
Publisher: Public Library of Science
Section: Research Article},
	keywords = {Classification, Random forest, Forests, Studies, Trees, Decision trees, Algorithms, Artificial intelligence, Bioinformatics, Biometrics, Breast cancer, Colorectal cancer, Environmental, Epidemiology, Error analysis, Forecasting, Information processing, Mathematical models, Mean squared prediction error, Medical research, Normal distribution, Parameter estimation, Parameter identification, Performance prediction, Prostate cancer, Research methodology, Sampling, Simulation and modeling, Tuning, Variables},
	pages = {e0201904},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/EKSXMNZP/Janitza and Hornung ⨯ - 2018 - On the overestimation of random forest’s out-of-bag error.pdf:application/pdf},
}

@misc{bischl_mlrmbo_2018,
	title = {{mlrMBO}: {A} {Modular} {Framework} for {Model}-{Based} {Optimization} of {Expensive} {Black}-{Box} {Functions}},
	shorttitle = {{mlrMBO}},
	url = {http://arxiv.org/abs/1703.03373},
	doi = {10.48550/arXiv.1703.03373},
	abstract = {We present mlrMBO, a flexible and comprehensive R toolbox for model-based optimization (MBO), also known as Bayesian optimization, which addresses the problem of expensive black-box optimization by approximating the given objective function through a surrogate regression model. It is designed for both single- and multi-objective optimization with mixed continuous, categorical and conditional parameters. Additional features include multi-point batch proposal, parallelization, visualization, logging and error-handling. mlrMBO is implemented in a modular fashion, such that single components can be easily replaced or adapted by the user for specific use cases, e.g., any regression learner from the mlr toolbox for machine learning can be used, and infill criteria and infill optimizers are easily exchangeable. We empirically demonstrate that mlrMBO provides state-of-the-art performance by comparing it on different benchmark scenarios against a wide range of other optimizers, including DiceOptim, rBayesianOptimization, SPOT, SMAC, Spearmint, and Hyperopt.},
	urldate = {2025-02-26},
	publisher = {arXiv},
	author = {Bischl, Bernd and Richter, Jakob and Bossek, Jakob and Horn, Daniel and Thomas, Janek and Lang, Michel},
	month = dec,
	year = {2018},
	note = {arXiv:1703.03373 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/FFN8L7CA/Bischl et al. - 2018 - mlrMBO A Modular Framework for Model-Based Optimization of Expensive Black-Box Functions.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/CHP6ARWG/1703.html:text/html},
}

@incollection{coello_sequential_2011,
	address = {Berlin, Heidelberg},
	title = {Sequential {Model}-{Based} {Optimization} for {General} {Algorithm} {Configuration}},
	volume = {6683},
	isbn = {978-3-642-25565-6 978-3-642-25566-3},
	url = {http://link.springer.com/10.1007/978-3-642-25566-3_40},
	urldate = {2025-02-26},
	booktitle = {Learning and {Intelligent} {Optimization}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	editor = {Coello, Carlos A. Coello},
	year = {2011},
	doi = {10.1007/978-3-642-25566-3_40},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {507--523},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/WQAQDBBF/Hutter et al. - 2011 - Sequential Model-Based Optimization for General Algorithm Configuration.pdf:application/pdf},
}

@article{goldstein_random_2011,
	title = {Random {Forests} for {Genetic} {Association} {Studies}},
	volume = {10},
	issn = {1544-6115, 2194-6302},
	url = {https://www.degruyter.com/document/doi/10.2202/1544-6115.1691/html},
	doi = {10.2202/1544-6115.1691},
	abstract = {The Random Forests (RF) algorithm has become a commonly used machine learning algorithm for genetic association studies. It is well suited for genetic applications since it is both computationally efficient and models genetic causal mechanisms well. With its growing ubiquity, there has been inconsistent and less than optimal use of RF in the literature. The purpose of this review is to breakdown the theoretical and statistical basis of RF so that practitioners are able to apply it in their work. An emphasis is placed on showing how the various components contribute to bias and variance, as well as discussing variable importance measures. Applications specific to genetic studies are highlighted. To provide context, RF is compared to other commonly used machine learning algorithms.},
	language = {en},
	number = {1},
	urldate = {2025-02-26},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {Goldstein, Benjamin A and Polley, Eric C and Briggs, Farren B. S.},
	month = jan,
	year = {2011},
	file = {PDF:/Users/frankie/Zotero/storage/EHDRVTHH/Goldstein et al. - 2011 - Random Forests for Genetic Association Studies.pdf:application/pdf},
}

@book{muller_here_2020,
	title = {here: {A} {Simpler} {Way} to {Find} {Your} {Files}},
	url = {https://CRAN.R-project.org/package=here},
	author = {Müller, Kirill},
	year = {2020},
}

@article{wright_ranger_2017,
	title = {ranger: {A} {Fast} {Implementation} of {Random} {Forests} for {High} {Dimensional} {Data} in {C}++ and {R}},
	volume = {77},
	doi = {10.18637/jss.v077.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Wright, Marvin N. and Ziegler, Andreas},
	year = {2017},
	pages = {1--17},
}

@misc{allaire_quarto_2024,
	title = {Quarto},
	url = {https://github.com/quarto-dev/quarto-cli},
	author = {Allaire, J. J. and Teague, Charles and Scheidegger, Carlos and Xie, Yihui and Dervieux, Christophe and Woodhull, Gordon},
	month = nov,
	year = {2024},
	doi = {10.5281/zenodo.5960048},
}

@misc{strobl_danger_2008,
	title = {Danger: {High} {Power}! – {Exploring} the {Statistical} {Properties} of a {Test} for {Random} {Forest} {Variable} {Importance}},
	shorttitle = {Danger},
	url = {https://epub.ub.uni-muenchen.de/2111/},
	abstract = {Random forests have become a widely-used predictive model in many scientific disciplines within the past few years. Additionally, they are increasingly popular for assessing variable importance, e.g., in genetics and bioinformatics. We highlight both advantages and limitations of different variable importance scores and associated testing procedures, especially in the context of correlated predictor variables. For the test of Breiman and Cutler (2008), we investigate the statistical properties and find that the power of the test depends both on the sample size
and the number of trees, an arbitrarily chosen tuning parameter, leading to undesired results that nullify any significance judgments. Moreover, the specification of the null hypothesis of this test is discussed in the context of correlated predictor variables.},
	language = {eng},
	urldate = {2025-02-26},
	author = {Strobl, Carolin and Zeileis, Achim},
	month = jan,
	year = {2008},
	doi = {10.5282/ubm/epub.2111},
	note = {Volume: 17},
	file = {Full Text PDF:/Users/frankie/Zotero/storage/I3X77SL9/Strobl and Zeileis - 2008 - Danger High Power! – Exploring the Statistical Properties of a Test for Random Forest Variable Impo.pdf:application/pdf;Snapshot:/Users/frankie/Zotero/storage/ZIYBFGTH/2111.html:text/html},
}

@article{segal_machine_2003,
	title = {Machine {Learning} {Benchmarks} and {Random} {Forest} {Regression}},
	journal = {Technical Report, Center for Bioinformatics \& Molecular Biostatistics, University of California, San Francisco},
	author = {Segal, Mark},
	month = may,
	year = {2003},
}
